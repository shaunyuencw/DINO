{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55437b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.distributed as dist\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as pth_transforms\n",
    "from torchvision import models as torchvision_models\n",
    "\n",
    "import utils\n",
    "import vision_transformer as vits\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a21650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "    \"\"\"Linear layer to train on top of frozen features\"\"\"\n",
    "    def __init__(self, dim, num_labels=1000):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.linear = nn.Linear(dim, num_labels)\n",
    "        self.linear.weight.data.normal_(mean=0.0, std=0.01)\n",
    "        self.linear.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # linear layer\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "811825f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_network(val_loader, model, linear_classifier, n, avgpool):\n",
    "    linear_classifier.eval()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    header = 'Test:'\n",
    "    for inp, target in metric_logger.log_every(val_loader, 20, header):\n",
    "        # move to gpu\n",
    "        inp = inp.cuda(non_blocking=True)\n",
    "        target = target.cuda(non_blocking=True)\n",
    "\n",
    "        # forward\n",
    "        with torch.no_grad():\n",
    "            if \"vit\" in \"vit_base\":\n",
    "                intermediate_output = model.get_intermediate_layers(inp, n)\n",
    "                output = torch.cat([x[:, 0] for x in intermediate_output], dim=-1)\n",
    "                if avgpool:\n",
    "                    output = torch.cat((output.unsqueeze(-1), torch.mean(intermediate_output[-1][:, 1:], dim=1).unsqueeze(-1)), dim=-1)\n",
    "                    output = output.reshape(output.shape[0], -1)\n",
    "            else:\n",
    "                output = model(inp)\n",
    "        output = linear_classifier(output)\n",
    "        loss = nn.CrossEntropyLoss()(output, target)\n",
    "\n",
    "        if linear_classifier.num_labels >= 5:\n",
    "            acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "        else:\n",
    "            acc1, = utils.accuracy(output, target, topk=(1,))\n",
    "\n",
    "        batch_size = inp.shape[0]\n",
    "        metric_logger.update(loss=loss.item())\n",
    "        metric_logger.meters['acc1'].update(acc1.item(), n=batch_size)\n",
    "        if linear_classifier.num_labels >= 5:\n",
    "            metric_logger.meters['acc5'].update(acc5.item(), n=batch_size)\n",
    "    if linear_classifier.num_labels >= 5:\n",
    "        print('* Acc@1 {top1.global_avg:.3f} Acc@5 {top5.global_avg:.3f} loss {losses.global_avg:.3f}'\n",
    "          .format(top1=metric_logger.acc1, top5=metric_logger.acc5, losses=metric_logger.loss))\n",
    "    else:\n",
    "        print('* Acc@1 {top1.global_avg:.3f} loss {losses.global_avg:.3f}'\n",
    "          .format(top1=metric_logger.acc1, losses=metric_logger.loss))\n",
    "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c78b417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Pretext and Linear Classifier weights here\n",
    "\n",
    "PRETRAINED_WEIGHTS = \"models/checkpoint0200.pth\"\n",
    "LINEAR_WEIGHTS = \"models/checkpoint.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1fae993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take key teacher in provided checkpoint dict\n",
      "Pretrained weights found at models/checkpoint0200.pth and loaded with msg: _IncompatibleKeys(missing_keys=['head.weight', 'head.bias'], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = vits.__dict__['vit_base'](patch_size=16, num_classes=4)\n",
    "embed_dim = model.embed_dim * (4 + int(False))\n",
    "\n",
    "utils.load_pretrained_weights(model, PRETRAINED_WEIGHTS, 'teacher', 'vit_base', 16)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9158b929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found checkpoint at models/checkpoint.pth.tar\n",
      "Value is dict_keys(['linear.weight', 'linear.bias'])\n",
      "=> loaded 'state_dict' from checkpoint 'models/checkpoint.pth.tar' with msg <All keys matched successfully>\n",
      "=> loaded 'optimizer' from checkpoint: 'models/checkpoint.pth.tar'\n",
      "=> loaded 'scheduler' from checkpoint: 'models/checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "linear_classifier = LinearClassifier(embed_dim, num_labels=4)\n",
    "linear_classifier = linear_classifier.cuda()\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "# set optimizer\n",
    "optimizer = torch.optim.SGD(\n",
    "    linear_classifier.parameters(),\n",
    "    lr * (256 * utils.get_world_size()) / 256., # linear scaling rule\n",
    "    momentum=0.9,\n",
    "    weight_decay=0, # we do not apply weight decay\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 100, eta_min=0)\n",
    "\n",
    "to_restore = {\"epoch\": 0, \"best_acc\": 0.}\n",
    "utils.restart_from_checkpoint(\n",
    "    os.path.join(\"models\", \"checkpoint.pth.tar\"),\n",
    "    run_variables=to_restore,\n",
    "    state_dict=linear_classifier,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    ")\n",
    "\n",
    "start_epoch = to_restore[\"epoch\"]\n",
    "best_acc = to_restore[\"best_acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b74f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ preparing data ... ============\n",
    "test_transform = pth_transforms.Compose([\n",
    "    pth_transforms.Resize(256, interpolation=3),\n",
    "    pth_transforms.CenterCrop(224),\n",
    "    pth_transforms.ToTensor(),\n",
    "    pth_transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "dataset_test = datasets.ImageFolder(os.path.join(\"../data/ship_100train_500val_200test\", \"test\"), transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=256,\n",
    "    num_workers=16,\n",
    "    pin_memory=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d664d61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [0/4]  eta: 0:00:22  loss: 0.235036 (0.235036)  acc1: 88.281250 (88.281250)  time: 5.640758  data: 4.197881  max mem: 5518\n",
      "Test:  [3/4]  eta: 0:00:02  loss: 0.153946 (0.185878)  acc1: 93.750000 (92.625000)  time: 2.172544  data: 1.049648  max mem: 5518\n",
      "Test: Total time: 0:00:08 (2.227809 s / it)\n",
      "* Acc@1 92.625 loss 0.186\n",
      "Accuracy of the network on the 800 test images: 92.6%\n"
     ]
    }
   ],
   "source": [
    "test_stats = validate_network(test_loader, model, linear_classifier, 4, False)\n",
    "print(f\"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d79c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bbca8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
